{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto ML\n",
    "\n",
    "Note: This uses following Docker (quick&dirty) image: https://cloud.docker.com/u/freecraver/repository/docker/freecraver/autosklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import autosklearn.regression\n",
    "import pandas as pd\n",
    "\n",
    "data_path = \"YearPredictionMSD.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>timbre_avg1</th>\n",
       "      <th>timbre_avg2</th>\n",
       "      <th>timbre_avg3</th>\n",
       "      <th>timbre_avg4</th>\n",
       "      <th>timbre_avg5</th>\n",
       "      <th>timbre_avg6</th>\n",
       "      <th>timbre_avg7</th>\n",
       "      <th>timbre_avg8</th>\n",
       "      <th>timbre_avg9</th>\n",
       "      <th>...</th>\n",
       "      <th>timbre_cov69</th>\n",
       "      <th>timbre_cov70</th>\n",
       "      <th>timbre_cov71</th>\n",
       "      <th>timbre_cov72</th>\n",
       "      <th>timbre_cov73</th>\n",
       "      <th>timbre_cov74</th>\n",
       "      <th>timbre_cov75</th>\n",
       "      <th>timbre_cov76</th>\n",
       "      <th>timbre_cov77</th>\n",
       "      <th>timbre_cov78</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001</td>\n",
       "      <td>49.94357</td>\n",
       "      <td>21.47114</td>\n",
       "      <td>73.07750</td>\n",
       "      <td>8.74861</td>\n",
       "      <td>-17.40628</td>\n",
       "      <td>-13.09905</td>\n",
       "      <td>-25.01202</td>\n",
       "      <td>-12.23257</td>\n",
       "      <td>7.83089</td>\n",
       "      <td>...</td>\n",
       "      <td>13.01620</td>\n",
       "      <td>-54.40548</td>\n",
       "      <td>58.99367</td>\n",
       "      <td>15.37344</td>\n",
       "      <td>1.11144</td>\n",
       "      <td>-23.08793</td>\n",
       "      <td>68.40795</td>\n",
       "      <td>-1.82223</td>\n",
       "      <td>-27.46348</td>\n",
       "      <td>2.26327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>48.73215</td>\n",
       "      <td>18.42930</td>\n",
       "      <td>70.32679</td>\n",
       "      <td>12.94636</td>\n",
       "      <td>-10.32437</td>\n",
       "      <td>-24.83777</td>\n",
       "      <td>8.76630</td>\n",
       "      <td>-0.92019</td>\n",
       "      <td>18.76548</td>\n",
       "      <td>...</td>\n",
       "      <td>5.66812</td>\n",
       "      <td>-19.68073</td>\n",
       "      <td>33.04964</td>\n",
       "      <td>42.87836</td>\n",
       "      <td>-9.90378</td>\n",
       "      <td>-32.22788</td>\n",
       "      <td>70.49388</td>\n",
       "      <td>12.04941</td>\n",
       "      <td>58.43453</td>\n",
       "      <td>26.92061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001</td>\n",
       "      <td>50.95714</td>\n",
       "      <td>31.85602</td>\n",
       "      <td>55.81851</td>\n",
       "      <td>13.41693</td>\n",
       "      <td>-6.57898</td>\n",
       "      <td>-18.54940</td>\n",
       "      <td>-3.27872</td>\n",
       "      <td>-2.35035</td>\n",
       "      <td>16.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>3.03800</td>\n",
       "      <td>26.05866</td>\n",
       "      <td>-50.92779</td>\n",
       "      <td>10.93792</td>\n",
       "      <td>-0.07568</td>\n",
       "      <td>43.20130</td>\n",
       "      <td>-115.00698</td>\n",
       "      <td>-0.05859</td>\n",
       "      <td>39.67068</td>\n",
       "      <td>-0.66345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001</td>\n",
       "      <td>48.24750</td>\n",
       "      <td>-1.89837</td>\n",
       "      <td>36.29772</td>\n",
       "      <td>2.58776</td>\n",
       "      <td>0.97170</td>\n",
       "      <td>-26.21683</td>\n",
       "      <td>5.05097</td>\n",
       "      <td>-10.34124</td>\n",
       "      <td>3.55005</td>\n",
       "      <td>...</td>\n",
       "      <td>34.57337</td>\n",
       "      <td>-171.70734</td>\n",
       "      <td>-16.96705</td>\n",
       "      <td>-46.67617</td>\n",
       "      <td>-12.51516</td>\n",
       "      <td>82.58061</td>\n",
       "      <td>-72.08993</td>\n",
       "      <td>9.90558</td>\n",
       "      <td>199.62971</td>\n",
       "      <td>18.85382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001</td>\n",
       "      <td>50.97020</td>\n",
       "      <td>42.20998</td>\n",
       "      <td>67.09964</td>\n",
       "      <td>8.46791</td>\n",
       "      <td>-15.85279</td>\n",
       "      <td>-16.81409</td>\n",
       "      <td>-12.48207</td>\n",
       "      <td>-9.37636</td>\n",
       "      <td>12.63699</td>\n",
       "      <td>...</td>\n",
       "      <td>9.92661</td>\n",
       "      <td>-55.95724</td>\n",
       "      <td>64.92712</td>\n",
       "      <td>-17.72522</td>\n",
       "      <td>-1.49237</td>\n",
       "      <td>-7.50035</td>\n",
       "      <td>51.76631</td>\n",
       "      <td>7.88713</td>\n",
       "      <td>55.66926</td>\n",
       "      <td>28.74903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2001</td>\n",
       "      <td>50.54767</td>\n",
       "      <td>0.31568</td>\n",
       "      <td>92.35066</td>\n",
       "      <td>22.38696</td>\n",
       "      <td>-25.51870</td>\n",
       "      <td>-19.04928</td>\n",
       "      <td>20.67345</td>\n",
       "      <td>-5.19943</td>\n",
       "      <td>3.63566</td>\n",
       "      <td>...</td>\n",
       "      <td>6.59753</td>\n",
       "      <td>-50.69577</td>\n",
       "      <td>26.02574</td>\n",
       "      <td>18.94430</td>\n",
       "      <td>-0.33730</td>\n",
       "      <td>6.09352</td>\n",
       "      <td>35.18381</td>\n",
       "      <td>5.00283</td>\n",
       "      <td>-11.02257</td>\n",
       "      <td>0.02263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2001</td>\n",
       "      <td>50.57546</td>\n",
       "      <td>33.17843</td>\n",
       "      <td>50.53517</td>\n",
       "      <td>11.55217</td>\n",
       "      <td>-27.24764</td>\n",
       "      <td>-8.78206</td>\n",
       "      <td>-12.04282</td>\n",
       "      <td>-9.53930</td>\n",
       "      <td>28.61811</td>\n",
       "      <td>...</td>\n",
       "      <td>11.63681</td>\n",
       "      <td>25.44182</td>\n",
       "      <td>134.62382</td>\n",
       "      <td>21.51982</td>\n",
       "      <td>8.17570</td>\n",
       "      <td>35.46251</td>\n",
       "      <td>11.57736</td>\n",
       "      <td>4.50056</td>\n",
       "      <td>-4.62739</td>\n",
       "      <td>1.40192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2001</td>\n",
       "      <td>48.26892</td>\n",
       "      <td>8.97526</td>\n",
       "      <td>75.23158</td>\n",
       "      <td>24.04945</td>\n",
       "      <td>-16.02105</td>\n",
       "      <td>-14.09491</td>\n",
       "      <td>8.11871</td>\n",
       "      <td>-1.87566</td>\n",
       "      <td>7.46701</td>\n",
       "      <td>...</td>\n",
       "      <td>18.03989</td>\n",
       "      <td>-58.46192</td>\n",
       "      <td>-65.56438</td>\n",
       "      <td>46.99856</td>\n",
       "      <td>-4.09602</td>\n",
       "      <td>56.37650</td>\n",
       "      <td>-18.29975</td>\n",
       "      <td>-0.30633</td>\n",
       "      <td>3.98364</td>\n",
       "      <td>-3.72556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2001</td>\n",
       "      <td>49.75468</td>\n",
       "      <td>33.99581</td>\n",
       "      <td>56.73846</td>\n",
       "      <td>2.89581</td>\n",
       "      <td>-2.92429</td>\n",
       "      <td>-26.44413</td>\n",
       "      <td>1.71392</td>\n",
       "      <td>-0.55644</td>\n",
       "      <td>22.08594</td>\n",
       "      <td>...</td>\n",
       "      <td>18.70812</td>\n",
       "      <td>5.20391</td>\n",
       "      <td>-27.75192</td>\n",
       "      <td>17.22100</td>\n",
       "      <td>-0.85210</td>\n",
       "      <td>-15.67150</td>\n",
       "      <td>-26.36257</td>\n",
       "      <td>5.48708</td>\n",
       "      <td>-9.13495</td>\n",
       "      <td>6.08680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2007</td>\n",
       "      <td>45.17809</td>\n",
       "      <td>46.34234</td>\n",
       "      <td>-40.65357</td>\n",
       "      <td>-2.47909</td>\n",
       "      <td>1.21253</td>\n",
       "      <td>-0.65302</td>\n",
       "      <td>-6.95536</td>\n",
       "      <td>-12.20040</td>\n",
       "      <td>17.02512</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.36742</td>\n",
       "      <td>-87.55285</td>\n",
       "      <td>-70.79677</td>\n",
       "      <td>76.57355</td>\n",
       "      <td>-7.71727</td>\n",
       "      <td>3.26926</td>\n",
       "      <td>-298.49845</td>\n",
       "      <td>11.49326</td>\n",
       "      <td>-89.21804</td>\n",
       "      <td>-15.09719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  timbre_avg1  timbre_avg2  timbre_avg3  timbre_avg4  timbre_avg5  \\\n",
       "0  2001     49.94357     21.47114     73.07750      8.74861    -17.40628   \n",
       "1  2001     48.73215     18.42930     70.32679     12.94636    -10.32437   \n",
       "2  2001     50.95714     31.85602     55.81851     13.41693     -6.57898   \n",
       "3  2001     48.24750     -1.89837     36.29772      2.58776      0.97170   \n",
       "4  2001     50.97020     42.20998     67.09964      8.46791    -15.85279   \n",
       "5  2001     50.54767      0.31568     92.35066     22.38696    -25.51870   \n",
       "6  2001     50.57546     33.17843     50.53517     11.55217    -27.24764   \n",
       "7  2001     48.26892      8.97526     75.23158     24.04945    -16.02105   \n",
       "8  2001     49.75468     33.99581     56.73846      2.89581     -2.92429   \n",
       "9  2007     45.17809     46.34234    -40.65357     -2.47909      1.21253   \n",
       "\n",
       "   timbre_avg6  timbre_avg7  timbre_avg8  timbre_avg9      ...       \\\n",
       "0    -13.09905    -25.01202    -12.23257      7.83089      ...        \n",
       "1    -24.83777      8.76630     -0.92019     18.76548      ...        \n",
       "2    -18.54940     -3.27872     -2.35035     16.07017      ...        \n",
       "3    -26.21683      5.05097    -10.34124      3.55005      ...        \n",
       "4    -16.81409    -12.48207     -9.37636     12.63699      ...        \n",
       "5    -19.04928     20.67345     -5.19943      3.63566      ...        \n",
       "6     -8.78206    -12.04282     -9.53930     28.61811      ...        \n",
       "7    -14.09491      8.11871     -1.87566      7.46701      ...        \n",
       "8    -26.44413      1.71392     -0.55644     22.08594      ...        \n",
       "9     -0.65302     -6.95536    -12.20040     17.02512      ...        \n",
       "\n",
       "   timbre_cov69  timbre_cov70  timbre_cov71  timbre_cov72  timbre_cov73  \\\n",
       "0      13.01620     -54.40548      58.99367      15.37344       1.11144   \n",
       "1       5.66812     -19.68073      33.04964      42.87836      -9.90378   \n",
       "2       3.03800      26.05866     -50.92779      10.93792      -0.07568   \n",
       "3      34.57337    -171.70734     -16.96705     -46.67617     -12.51516   \n",
       "4       9.92661     -55.95724      64.92712     -17.72522      -1.49237   \n",
       "5       6.59753     -50.69577      26.02574      18.94430      -0.33730   \n",
       "6      11.63681      25.44182     134.62382      21.51982       8.17570   \n",
       "7      18.03989     -58.46192     -65.56438      46.99856      -4.09602   \n",
       "8      18.70812       5.20391     -27.75192      17.22100      -0.85210   \n",
       "9      -4.36742     -87.55285     -70.79677      76.57355      -7.71727   \n",
       "\n",
       "   timbre_cov74  timbre_cov75  timbre_cov76  timbre_cov77  timbre_cov78  \n",
       "0     -23.08793      68.40795      -1.82223     -27.46348       2.26327  \n",
       "1     -32.22788      70.49388      12.04941      58.43453      26.92061  \n",
       "2      43.20130    -115.00698      -0.05859      39.67068      -0.66345  \n",
       "3      82.58061     -72.08993       9.90558     199.62971      18.85382  \n",
       "4      -7.50035      51.76631       7.88713      55.66926      28.74903  \n",
       "5       6.09352      35.18381       5.00283     -11.02257       0.02263  \n",
       "6      35.46251      11.57736       4.50056      -4.62739       1.40192  \n",
       "7      56.37650     -18.29975      -0.30633       3.98364      -3.72556  \n",
       "8     -15.67150     -26.36257       5.48708      -9.13495       6.08680  \n",
       "9       3.26926    -298.49845      11.49326     -89.21804     -15.09719  \n",
       "\n",
       "[10 rows x 91 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = pd.read_csv(data_path, header=None)\n",
    "df_data.columns = ['year'] + ['timbre_avg' + str(i) for i in range(1,13)] + ['timbre_cov' + str(i) for i in range(1,79)]\n",
    "# What is timbre? refer to http://docs.echonest.com.s3-website-us-east-1.amazonaws.com/_static/AnalyzeDocumentation.pdf\n",
    "df_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split up according to dataset description (i.e. 'producer effect' is avoided)\n",
    "df_train = df_data.loc[:463715,:]\n",
    "df_test = df_data.loc[463715:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] [2019-01-06 15:48:27,936:AutoMLSMBO(1)::7a4e05abbf5169d80d7b9cf067750fed] Could not find meta-data directory /usr/local/lib/python3.6/dist-packages/autosklearn/metalearning/files/r2_regression_dense\n",
      "[WARNING] [2019-01-06 15:48:27,940:EnsembleBuilder(1):7a4e05abbf5169d80d7b9cf067750fed] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-01-06 15:48:27,951:EnsembleBuilder(1):7a4e05abbf5169d80d7b9cf067750fed] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-01-06 15:48:29,956:EnsembleBuilder(1):7a4e05abbf5169d80d7b9cf067750fed] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-01-06 15:48:31,964:EnsembleBuilder(1):7a4e05abbf5169d80d7b9cf067750fed] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-01-06 15:48:33,971:EnsembleBuilder(1):7a4e05abbf5169d80d7b9cf067750fed] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-01-06 15:48:35,977:EnsembleBuilder(1):7a4e05abbf5169d80d7b9cf067750fed] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-01-06 15:48:37,985:EnsembleBuilder(1):7a4e05abbf5169d80d7b9cf067750fed] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-01-06 15:48:39,992:EnsembleBuilder(1):7a4e05abbf5169d80d7b9cf067750fed] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-01-06 15:48:41,999:EnsembleBuilder(1):7a4e05abbf5169d80d7b9cf067750fed] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-01-06 15:48:44,006:EnsembleBuilder(1):7a4e05abbf5169d80d7b9cf067750fed] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-01-06 15:48:46,014:EnsembleBuilder(1):7a4e05abbf5169d80d7b9cf067750fed] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-01-06 15:48:48,021:EnsembleBuilder(1):7a4e05abbf5169d80d7b9cf067750fed] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-01-06 15:48:50,027:EnsembleBuilder(1):7a4e05abbf5169d80d7b9cf067750fed] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-01-06 15:48:52,035:EnsembleBuilder(1):7a4e05abbf5169d80d7b9cf067750fed] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-01-06 15:48:54,041:EnsembleBuilder(1):7a4e05abbf5169d80d7b9cf067750fed] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-01-06 15:48:56,048:EnsembleBuilder(1):7a4e05abbf5169d80d7b9cf067750fed] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-01-06 15:48:58,055:EnsembleBuilder(1):7a4e05abbf5169d80d7b9cf067750fed] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-01-06 15:49:00,061:EnsembleBuilder(1):7a4e05abbf5169d80d7b9cf067750fed] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-01-06 15:49:02,069:EnsembleBuilder(1):7a4e05abbf5169d80d7b9cf067750fed] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-01-06 15:49:04,076:EnsembleBuilder(1):7a4e05abbf5169d80d7b9cf067750fed] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-01-06 15:49:06,085:EnsembleBuilder(1):7a4e05abbf5169d80d7b9cf067750fed] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-01-06 15:49:08,092:EnsembleBuilder(1):7a4e05abbf5169d80d7b9cf067750fed] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-01-06 15:49:10,102:EnsembleBuilder(1):7a4e05abbf5169d80d7b9cf067750fed] No models better than random - using Dummy Score!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoSklearnRegressor(delete_output_folder_after_terminate=True,\n",
       "           delete_tmp_folder_after_terminate=True,\n",
       "           disable_evaluator_output=False, ensemble_memory_limit=4096,\n",
       "           ensemble_nbest=50, ensemble_size=50, exclude_estimators=None,\n",
       "           exclude_preprocessors=None, get_smac_object_callback=None,\n",
       "           include_estimators=None, include_preprocessors=None,\n",
       "           initial_configurations_via_metalearning=25, logging_config=None,\n",
       "           ml_memory_limit=4096, output_folder=None,\n",
       "           per_run_time_limit=360, resampling_strategy='holdout',\n",
       "           resampling_strategy_arguments=None, seed=1, shared_mode=False,\n",
       "           smac_scenario_args=None, time_left_for_this_task=600,\n",
       "           tmp_folder=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls = autosklearn.regression.AutoSklearnRegressor(\n",
    "    time_left_for_this_task=600,\n",
    "    per_run_time_limit=360,\n",
    "    ensemble_memory_limit=4096,\n",
    "    ml_memory_limit=4096)\n",
    "\n",
    "df_sample = df_train.sample(10000)\n",
    "\n",
    "X_train = df_sample.loc[:, df_sample.columns != 'year'].values\n",
    "y_train = df_sample['year'].values\n",
    "\n",
    "cls.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test.loc[:, df_test.columns != \"year\"]\n",
    "y_test = df_test['year']\n",
    "\n",
    "yhat = cls.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 87.80418680677062\n",
      "RMSE: 9.370388829006544\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "mse = mean_squared_error(df_test['year'], yhat)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", math.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'auto-sklearn results:\\n  Dataset name: 7a4e05abbf5169d80d7b9cf067750fed\\n  Metric: r2\\n  Best validation score: 0.243133\\n  Number of target algorithm runs: 26\\n  Number of successful target algorithm runs: 23\\n  Number of crashed target algorithm runs: 0\\n  Number of target algorithms that exceeded the time limit: 1\\n  Number of target algorithms that exceeded the memory limit: 2\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cls.cv_results_\n",
    "cls.sprint_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[(0.440000, SimpleRegressionPipeline({'categorical_encoding:__choice__': 'one_hot_encoding', 'imputation:strategy': 'most_frequent', 'preprocessor:__choice__': 'feature_agglomeration', 'regressor:__choice__': 'ridge_regression', 'rescaling:__choice__': 'robust_scaler', 'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'False', 'preprocessor:feature_agglomeration:affinity': 'manhattan', 'preprocessor:feature_agglomeration:linkage': 'average', 'preprocessor:feature_agglomeration:n_clusters': 103, 'preprocessor:feature_agglomeration:pooling_func': 'median', 'regressor:ridge_regression:alpha': 1.4467302287296093, 'regressor:ridge_regression:fit_intercept': 'True', 'regressor:ridge_regression:tol': 0.0029020092462586676, 'rescaling:robust_scaler:q_max': 0.8385049904773149, 'rescaling:robust_scaler:q_min': 0.17362159033588861},\\ndataset_properties={\\n  'task': 4,\\n  'sparse': False,\\n  'multilabel': False,\\n  'multiclass': False,\\n  'target_type': 'regression',\\n  'signed': False})),\\n(0.300000, SimpleRegressionPipeline({'categorical_encoding:__choice__': 'no_encoding', 'imputation:strategy': 'most_frequent', 'preprocessor:__choice__': 'pca', 'regressor:__choice__': 'adaboost', 'rescaling:__choice__': 'minmax', 'preprocessor:pca:keep_variance': 0.9021106725246424, 'preprocessor:pca:whiten': 'False', 'regressor:adaboost:learning_rate': 1.0487810146087861, 'regressor:adaboost:loss': 'square', 'regressor:adaboost:max_depth': 9, 'regressor:adaboost:n_estimators': 480},\\ndataset_properties={\\n  'task': 4,\\n  'sparse': False,\\n  'multilabel': False,\\n  'multiclass': False,\\n  'target_type': 'regression',\\n  'signed': False})),\\n(0.200000, SimpleRegressionPipeline({'categorical_encoding:__choice__': 'one_hot_encoding', 'imputation:strategy': 'mean', 'preprocessor:__choice__': 'no_preprocessing', 'regressor:__choice__': 'random_forest', 'rescaling:__choice__': 'standardize', 'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True', 'regressor:random_forest:bootstrap': 'True', 'regressor:random_forest:criterion': 'mse', 'regressor:random_forest:max_depth': 'None', 'regressor:random_forest:max_features': 1.0, 'regressor:random_forest:max_leaf_nodes': 'None', 'regressor:random_forest:min_impurity_decrease': 0.0, 'regressor:random_forest:min_samples_leaf': 1, 'regressor:random_forest:min_samples_split': 2, 'regressor:random_forest:min_weight_fraction_leaf': 0.0, 'regressor:random_forest:n_estimators': 100, 'categorical_encoding:one_hot_encoding:minimum_fraction': 0.01},\\ndataset_properties={\\n  'task': 4,\\n  'sparse': False,\\n  'multilabel': False,\\n  'multiclass': False,\\n  'target_type': 'regression',\\n  'signed': False})),\\n(0.060000, SimpleRegressionPipeline({'categorical_encoding:__choice__': 'no_encoding', 'imputation:strategy': 'median', 'preprocessor:__choice__': 'select_percentile_regression', 'regressor:__choice__': 'random_forest', 'rescaling:__choice__': 'robust_scaler', 'preprocessor:select_percentile_regression:percentile': 72.50921030129456, 'preprocessor:select_percentile_regression:score_func': 'mutual_info', 'regressor:random_forest:bootstrap': 'True', 'regressor:random_forest:criterion': 'mse', 'regressor:random_forest:max_depth': 'None', 'regressor:random_forest:max_features': 0.18845237489951716, 'regressor:random_forest:max_leaf_nodes': 'None', 'regressor:random_forest:min_impurity_decrease': 0.0, 'regressor:random_forest:min_samples_leaf': 5, 'regressor:random_forest:min_samples_split': 11, 'regressor:random_forest:min_weight_fraction_leaf': 0.0, 'regressor:random_forest:n_estimators': 100, 'rescaling:robust_scaler:q_max': 0.8941577571190388, 'rescaling:robust_scaler:q_min': 0.1397004468733128},\\ndataset_properties={\\n  'task': 4,\\n  'sparse': False,\\n  'multilabel': False,\\n  'multiclass': False,\\n  'target_type': 'regression',\\n  'signed': False})),\\n]\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls.show_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
